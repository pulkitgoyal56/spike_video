{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b134289e-f3fa-4287-b5d2-afb845df45fc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>DEPENDENCIES</b>\n",
    "    <ul>\n",
    "        <li> numpy\n",
    "        <li> scipy\n",
    "        <li> matplotlib\n",
    "        <li> mat73\n",
    "        <li> moviepy\n",
    "    <\\ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856434b1-008f-4e6d-bb7a-a1f289d1352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37cd2f5d-d60d-42fb-956a-57c673a44c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy as sc\n",
    "# import scipy.signal as sg\n",
    "from scipy.signal import argrelmax\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c115ce20-5aff-4b23-8f93-3587898d0fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123d37a2-e20b-4499-be51-2d6d09ae0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ac56d55-f1dc-46bf-9aa6-532802107abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoClip, VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip, CompositeAudioClip, clips_array, vfx\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea91f7b6-287c-4435-a302-8c4e8ecedd95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc2d9d1-5dfc-4760-8670-9f99090d6c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'pupil_times', 'stim_off', 'stim_on', 'times', 'trace'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = mat73.loadmat(\"../data/cell-ID-6.mat\")[\"ephys\"]\n",
    "# trace       = filtered data (artifact replaced with nans)\n",
    "# times       = times of the recording (in sec)\n",
    "# stim_on     = stimuli onset (in sec)\n",
    "# stim_off    = stimuli offset (in sec)\n",
    "# pupil_times = the time vector of the video (in sec)\n",
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162569a2-d714-4524-b7fc-64e0873774fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video = VideoFileClip(r\"../data/GB0002 22-05-31 11-03-34_.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0592bbdd-504b-4d73-bbbf-586660c9274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_sampling_freq = np.argwhere(data_dict[\"times\"] >= 1)[0][0]\n",
    "video_frame_rate = int(np.ceil(video.fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f2030a-9bda-4864-8f78-07c1b0a4e489",
   "metadata": {},
   "source": [
    "```\n",
    "> Recording frequency ~ 25000 Hz  \n",
    "> Frame rate of video ~ 20 fps\n",
    "```\n",
    "<!-- 102.400264 frames/s -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f9e4709-7ad3-4e89-9522-394569130f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_threshold = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5cef0-668b-498d-8a2a-926369c18bbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a693c50-75ab-4646-a111-1847a05a295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_indices = np.squeeze(argrelmax(data_dict[\"trace\"]))\n",
    "spike_times = data_dict[\"times\"][peak_indices[data_dict[\"trace\"][peak_indices] > spike_threshold]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fcf8e8-96e4-4f8d-8c2e-30c40b1e1006",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873c1752-0550-4f33-9205-e09b29d5468e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_spikes(t_b, t_a=0, ax=None, shade_stimulus=False, indicate_spikes=False, plot=True):\n",
    "    \"\"\"Plot the spike waveform.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t_b : float\n",
    "        Window start time (s).\n",
    "    t_a : float, optional\n",
    "        Window start time (s), by default 0.0.\n",
    "    ax : matplotlib.axes.Axes, optional\n",
    "        Axis to plot on, by default None.\n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16, 4), dpi=40)\n",
    "\n",
    "    a = int(t_a * spike_sampling_freq)\n",
    "    n = int((t_b - t_a) * spike_sampling_freq) # Window size\n",
    "\n",
    "    ax.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "    if shade_stimulus:\n",
    "        for son, soff in zip(data_dict[\"stim_on\"], data_dict[\"stim_off\"]):\n",
    "            if son*spike_sampling_freq >= a+n: break\n",
    "            soff = min(soff, (a+n)/spike_sampling_freq)\n",
    "            ax.axvspan(son, soff, color='pink', alpha=0.1)\n",
    "\n",
    "    if indicate_spikes:\n",
    "        for spike_time in spike_times[(spike_times >= t_a) & (spike_times < t_b)]:\n",
    "            ax.axvline(spike_time, color='g', linestyle='-.')\n",
    "    \n",
    "    if plot:\n",
    "        ax.plot(data_dict[\"times\"][a:a+n], data_dict[\"trace\"][a:a+n])\n",
    "    \n",
    "    return data_dict[\"times\"][a:a+n], data_dict[\"trace\"][a:a+n]\n",
    "\n",
    "    ## FFT\n",
    "    # ax[1].axhline(0, color='k', linestyle='--')\n",
    "    # ax[1].plot(np.fft.fftshift(np.fft.fftfreq(n, 1/spike_sampling_freq)), np.abs(np.fft.fftshift(np.fft.fft(data_dict[\"trace\"][a:a+n]))))\n",
    "    # ax[1].set_xticks(np.arange(-int(spike_sampling_freq/2), int(spike_sampling_freq/2), 1000))\n",
    "    # ax[1].set_xlim([-spike_sampling_freq/2, spike_sampling_freq/2]);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75a9e231-6bb5-41ce-a3f6-c7310c411115",
   "metadata": {},
   "source": [
    "plot_spikes(19, 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0898f7cf-1c07-4746-b076-3a635afd1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_video(t_b, t_a=0.0, speed=1.0, t_w=1.0, fps=None, transition='roll', save=True, output=\".temp/__temp__.mp4\"):\n",
    "    \"\"\"Generate spike video\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t_b : float\n",
    "        Window start time (s).\n",
    "    t_a : float, optional\n",
    "        Window start time (s), by default 0.0.\n",
    "    speed : float, optional\n",
    "        Playback speed, by default 1.0.\n",
    "    t_w : float, optional\n",
    "        Window size (s) if transition is 'window', by default 1.0.\n",
    "    fps : int, optional\n",
    "        Frames per second, by default None.\n",
    "    transition : {'roll', 'window'}, optional, optional\n",
    "        Type of video animation, by default 'roll'\n",
    "        'roll' - Growing spike waveform.\n",
    "        'window' - Shifting window waveform.\n",
    "    save : bool, optional\n",
    "        Save video as .mp4?, by default True.\n",
    "    output : str, optional\n",
    "        Output file name, by default 'roll.wav'.\n",
    "    \"\"\"\n",
    "    if speed is None:\n",
    "        if transition == 'roll':\n",
    "            speed = round((t_b - t_a)/5.0, 3) #1-5\n",
    "        elif transition == 'window':\n",
    "            speed = round(t_w/1.0, 3)     #1-5\n",
    "\n",
    "    sfps = max(24, np.ceil(fps if fps else min(120, spike_sampling_freq*speed, video_frame_rate*speed)))\n",
    "\n",
    "    if transition == 'roll': t_w = 0\n",
    "    print(f\"> Estimated Video Length ~ {(t_b - t_w - t_a)/speed:.2f}s @ {sfps:>5} fps  | [{t_a:.3f}s, {t_b:.3f}s] @ {speed}x <{transition[0]}> -- `{output if output else f'{transition}.mp4'}`\")\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 4), dpi=40)\n",
    "    ax.set_ylim(-0.001, 0.002)\n",
    "    ax.axis('off')\n",
    "\n",
    "    if transition == 'window':\n",
    "        def make_frame(t):\n",
    "            ax.clear()\n",
    "            ax.set_xlim(t_a + t*speed, t_a + t_w + t*speed)        \n",
    "            plot_spikes(t_a + t_w + t*speed, t_a + t*speed, ax=ax, shade_stimulus=True, indicate_spikes=False, plot=False)\n",
    "            return mplfig_to_npimage(fig)\n",
    "        \n",
    "        video = VideoClip(make_frame, duration=(t_b - t_w - t_a)/speed)\n",
    "        if save: video.write_videofile(output if output else f\"{transition}.mp4\", fps=sfps, verbose=False, logger=None)\n",
    "        # video.ipython_display(fps=sfps, loop=False, autoplay=True)\n",
    "        \n",
    "    elif transition == 'roll':\n",
    "        ax.set_xlim(t_a, t_b)\n",
    "\n",
    "        x, y = plot_spikes(t_b, t_a, ax=ax, shade_stimulus=True, indicate_spikes=False, plot=False)\n",
    "        line, = ax.plot(x, y)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        def update(frame):\n",
    "            f = int(frame*spike_sampling_freq*speed/sfps)\n",
    "            line.set_data(x[:f], y[:f])\n",
    "            return line,\n",
    "\n",
    "        video = animation.FuncAnimation(fig, update, frames=int((t_b - t_a)/speed*sfps), interval=int(1000/sfps), blit=True)\n",
    "        if save: video.save(output if output else f\"{transition}.mp4\", writer=animation.FFMpegWriter(fps=sfps))\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return video, sfps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64545e4d-f2c2-4501-ad28-16fdfb05b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(t_b, t_a=0.0, speed=1.0, tone_frequency=200, tone_duration=0.002, save=True, output='.temp/__temp__.wav'):\n",
    "    \"\"\" Generate spike audio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t_b : float\n",
    "        Window start time (s).\n",
    "    t_a : float, optional\n",
    "        Window start time (s), by default 0.0.\n",
    "    speed : float, optional\n",
    "        Playback speed, by default 1.0.\n",
    "    tone_frequency : int, optional\n",
    "        Frequency of spike chirp, by default 440.\n",
    "    tone_duration : float, optional\n",
    "        Duration of spike chirp, by default 0.002.\n",
    "    save : bool, optional\n",
    "        Save audio as .wav?, by default True.\n",
    "    output : str, optional\n",
    "        Output file name, by default 'roll.wav'.\n",
    "    \"\"\"\n",
    "    if speed is None: speed = round((t_b - t_a)/5.0, 3) #1-5\n",
    "    \n",
    "    afps = int(spike_sampling_freq*speed)\n",
    "    if tone_frequency >= afps/2:\n",
    "        raise ValueError(f\"Speed too low! Min Speed - {2*tone_frequency/spike_sampling_freq}\")\n",
    "    \n",
    "    print(f\"> Estimated Audio Length ~ {(t_b - t_a)/speed:.2f}s @ {afps:>5} afps | [{t_a:.3f}s, {t_b:.3f}s] @ {speed}x     -- `{output}`\")\n",
    "    \n",
    "    n = int((t_b - t_a) * spike_sampling_freq)\n",
    "    #x = np.arange(n)*(t_b - t_a)/(n-1)/speed\n",
    "    \n",
    "    def add_chirp(signal, index):\n",
    "        if index + int(spike_sampling_freq*tone_duration) < signal.size:\n",
    "            signal[index:index+int(spike_sampling_freq*tone_duration)] = np.sin(2*np.pi*tone_frequency/speed*np.linspace(0, tone_duration, int(spike_sampling_freq*tone_duration)))\n",
    "    \n",
    "    chirp_indices = ((spike_times[(spike_times >= t_a) & (spike_times < t_b)] - t_a) * spike_sampling_freq).astype(np.int)\n",
    "\n",
    "    y = np.zeros(n)\n",
    "    for chirp_index in chirp_indices:\n",
    "        add_chirp(y, chirp_index)\n",
    "\n",
    "    audio = np.array(y/max(y), dtype=np.float32)\n",
    "    if save: write(output, afps, audio)\n",
    "    \n",
    "    return audio, afps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3f4d104-1faf-4cc8-90a6-1b9625a3dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_video(t_b, t_a=0.0, speed=1.0, fps=None, output=\"spike.mp4\"):\n",
    "    _, afps = generate_audio(t_b, t_a, speed, output=\".temp/__temp__.wav\")\n",
    "    _, sfps = generate_video(t_b, t_a, speed, fps=fps, save=True, output=\".temp/__temp__.mp4\")\n",
    "    \n",
    "    spike_video = VideoFileClip(\".temp/__temp__.mp4\")\n",
    "    spike_audio = AudioFileClip(\".temp/__temp__.wav\")\n",
    "    spike_video.audio = CompositeAudioClip([spike_audio])\n",
    "    video_x = video.subclip(t_a, t_b).speedx(speed).set_fps(sfps)\n",
    "    \n",
    "    txt_clip = TextClip(f\"x{speed}\", fontsize=75, color='black')\n",
    "    txt_clip = txt_clip.set_position((\"right\", \"top\")).set_duration((t_b-t_a)/speed)\n",
    "    \n",
    "    clips_array([[CompositeVideoClip([video_x, txt_clip])], [spike_video]]).write_videofile(output) #, verbose=False, logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "035321cf-256f-411d-a19d-eb639bf26d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Estimated Audio Length ~ 7.50s @ 10000 afps | [0.000s, 3.000s] @ 0.4x     -- `.temp/__temp__.wav`\n",
      "> Estimated Video Length ~ 7.50s @    24 fps  | [0.000s, 3.000s] @ 0.4x <r> -- `.temp/__temp__.mp4`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video spike.mp4.\n",
      "MoviePy - Writing audio in spikeTEMP_MPY_wvf_snd.mp3\n",
      "MoviePy - Done.\n",
      "Moviepy - Writing video spike.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready spike.mp4\n"
     ]
    }
   ],
   "source": [
    "spike_video(3, 0, 0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
